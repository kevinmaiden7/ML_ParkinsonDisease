{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning Project on UCI Parkinsons Telemonitoring Data Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importación de librerías:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install qgrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy.matlib as matlib\n",
    "\n",
    "from numpy import random\n",
    "import math\n",
    "\n",
    "import pandas as pd\n",
    "import qgrid\n",
    "\n",
    "import scipy as sc\n",
    "from scipy.spatial import distance\n",
    "from scipy import stats\n",
    "\n",
    "#algunas advertencias que queremos evitar\n",
    "import warnings\n",
    "warnings.filterwarnings(\"always\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos la base de datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cargamos la bd que está en un archivo .data y ahora la podemos manejar de forma matricial\n",
    "db = np.loadtxt('DB/parkinsons_updrs.data', delimiter=',', skiprows=1)  # Assuming ',' delimiter\n",
    "\n",
    "#X: Toma todas las filas (muestras) y las columnas 6-21 (características)\n",
    "X = db[:,6:22]\n",
    "#Y: Toma todas las filas y la columna 4, corresponde a la salida de la regresión\n",
    "Y = db[:,4]\n",
    "#G: Toma todas las filas y la columna 0, corresponde a la asociación en grupos del dataset\n",
    "G = db[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5875, 16)\n",
      "(5875,)\n",
      "(5875,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(Y.shape)\n",
    "print(G.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Medidas de error para evaluar los métodos de regresión:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mean Square Error\n",
    "def MSE(Y_est,Y):\n",
    "    N = np.size(Y)\n",
    "    mse = (1/N)*np.sum((Y_est.reshape(N,1) - Y.reshape(N,1))**2)\n",
    "    return mse\n",
    "\n",
    "#Mean Percentage Error\n",
    "def MAE(Y_est,Y):\n",
    "    N = np.size(Y)\n",
    "    mae = (1/N)*np.sum(abs(Y_est.reshape(N,1) - Y.reshape(N,1)))\n",
    "    return mae\n",
    "\n",
    "#Mean Absolute Percentage Error\n",
    "def MAPE(Y_est,Y):\n",
    "    N = np.size(Y)\n",
    "    mape = (1/N)*np.sum(abs((Y_est.reshape(N,1) - Y.reshape(N,1))/Y.reshape(N,1)))\n",
    "    return mape\n",
    "\n",
    "#Root Mean Square Error\n",
    "def RMSE(Y_est,Y):\n",
    "    N = np.size(Y)\n",
    "    rmse = math.sqrt((1/N)*np.sum((Y_est.reshape(N,1) - Y.reshape(N,1))**2))\n",
    "    return rmse\n",
    "\n",
    "#Coeficiente de determinación\n",
    "def R2(Y_est,Y):\n",
    "    N = np.size(Y)\n",
    "    average = np.sum(Y.reshape(N,1))/N\n",
    "    SST = np.sum((average - Y.reshape(N,1))**2)\n",
    "    SSE = np.sum((Y_est.reshape(N,1) - Y.reshape(N,1))**2)\n",
    "    R2 = 1 - (SSE/SST)\n",
    "    return R2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regresión Polinomial Múltiple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import preprocessing\n",
    "\n",
    "def PolynomialRegression(degree):\n",
    "    iterations = 10\n",
    "    random.seed(19680801)\n",
    "    errorTrainMAE = np.zeros(iterations)\n",
    "    errorTrainR2 = np.zeros(iterations)\n",
    "    errorValMAE = np.zeros(iterations)\n",
    "    errorValR2 = np.zeros(iterations)\n",
    "\n",
    "    gss = GroupShuffleSplit(n_splits=iterations, train_size=.7)\n",
    "    j=0\n",
    "    for train_idx, test_idx in gss.split(X, Y, G):\n",
    "        Xtrain = X[train_idx,:]\n",
    "        Ytrain = Y[train_idx]\n",
    "        Xtest = X[test_idx,:]\n",
    "        Ytest = Y[test_idx]\n",
    "\n",
    "        #Normalizamos los datos\n",
    "        #media = np.mean(Xtrain)\n",
    "        #desvia = np.std(Xtrain)\n",
    "        #Xtrain = sc.stats.stats.zscore(Xtrain)\n",
    "        #Xtest = (Xtest - np.matlib.repmat(media, Xtest.shape[0], 1))/np.matlib.repmat(desvia, Xtest.shape[0], 1)\n",
    "        \n",
    "        scaler = preprocessing.StandardScaler().fit(Xtrain)\n",
    "        Xtrain = scaler.transform(Xtrain)\n",
    "        Xtest = scaler.transform(Xtest)\n",
    "\n",
    "        #Creación del modelo\n",
    "        #polynomial_features = PolynomialFeatures(degree=degree)\n",
    "        #Xtrain_poly = polynomial_features.fit_transform(Xtrain) # transforms the existing features to higher degree features.\n",
    "\n",
    "        # fit the transformed features to Linear Regression\n",
    "        #model = LinearRegression()\n",
    "        #model.fit(Xtrain_poly, Ytrain)\n",
    "        \n",
    "        model = Pipeline([('poly', PolynomialFeatures(degree=degree)),\n",
    "                  ('linear', LinearRegression(fit_intercept=False))])\n",
    "        \n",
    "        model.fit(Xtrain, Ytrain)\n",
    "        \n",
    "        #Validación\n",
    "        YestTrain = model.predict(Xtrain)\n",
    "        YestVal = model.predict(Xtest)\n",
    "        #YestVal = model.predict(polynomial_features.fit_transform(Xtest))\n",
    "        #Uso del modelo previamente entrenado para hacer predicciones con las muestras de test\n",
    "        #Se escalan los datos de acuerdo a como se entrenó el modelo para predecir correctamente\n",
    "\n",
    "        #Evaluamos las predicciones del modelo con los datos de Ytest\n",
    "        errorTrainMAE[j] = MAE(YestTrain, Ytrain)\n",
    "        errorTrainR2[j] = R2(YestTrain, Ytrain)\n",
    "        errorValMAE[j] = MAE(YestVal, Ytest)\n",
    "        errorValR2[j] = R2(YestVal, Ytest)\n",
    "        j += 1\n",
    "\n",
    "    #\n",
    "    return(np.mean(errorTrainMAE), np.mean(errorTrainR2), np.mean(errorValMAE), np.mean(errorValR2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5.461242028272216, 0.3161529298022627, 8.240103665000163, -2.519604188875836)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PolynomialRegression(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Redes Neuronales Artificiales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn import preprocessing\n",
    "\n",
    "#from sklearn.metrics import mean_absolute_error\n",
    "#from sklearn.metrics import r2_score\n",
    "\n",
    "def ANN(layers, neurons, epochs):\n",
    "    iterations = 10\n",
    "    random.seed(19680801)\n",
    "    errorMAE = np.zeros(iterations)\n",
    "    errorMSE = np.zeros(iterations)\n",
    "    errorRMSE = np.zeros(iterations)\n",
    "    errorR2 = np.zeros(iterations)\n",
    "\n",
    "    gss = GroupShuffleSplit(n_splits=iterations, train_size=0.7)\n",
    "    j=0\n",
    "    for train_idx, test_idx in gss.split(X, Y, G):\n",
    "        Xtrain = X[train_idx,:]\n",
    "        Ytrain = Y[train_idx]\n",
    "        Xtest = X[test_idx,:]\n",
    "        Ytest = Y[test_idx]\n",
    "\n",
    "        #Normalizamos los datos\n",
    "        media = np.mean(Xtrain, axis=0)\n",
    "        desvia = np.std(Xtrain, axis=0)\n",
    "        #Xtrain = sc.stats.stats.zscore(Xtrain)\n",
    "        Xtrain = preprocessing.scale(Xtrain)\n",
    "        Xtest = (Xtest - np.matlib.repmat(media, Xtest.shape[0], 1))/np.matlib.repmat(desvia, Xtest.shape[0], 1)\n",
    "\n",
    "        #Creación del modelo y entrenamiento        \n",
    "        numberOfNeurons = []\n",
    "        for i in range(layers):\n",
    "            numberOfNeurons.append(neurons)\n",
    "            \n",
    "        mlp = MLPRegressor(hidden_layer_sizes=numberOfNeurons, activation='tanh', max_iter=epochs).fit(Xtrain, Ytrain)\n",
    "\n",
    "        #Validación\n",
    "        Yest = mlp.predict(Xtest)\n",
    "\n",
    "        #Evaluamos las predicciones del modelo con los datos de Ytest\n",
    "        errorMAE[j] = MAE(Yest,Ytest)\n",
    "        errorMSE[j] = MSE(Yest,Ytest)\n",
    "        errorRMSE[j] = RMSE(Yest,Ytest)\n",
    "        errorR2[j] = R2(Yest,Ytest)\n",
    "        j += 1\n",
    "\n",
    "    return(np.mean(errorMAE), np.std(errorMAE), np.mean(errorMSE), np.std(errorMSE), np.mean(errorRMSE), np.std(errorRMSE), np.mean(errorR2), np.std(errorR2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ANN(3, 10, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resultados ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import qgrid\n",
    "df_types = pd.DataFrame({\n",
    "    'N. de capas ocultas' : pd.Series([1,1,1,2,2,2,3,3,3]),\n",
    "    'Neuronas por capa' : pd.Series([20,28,36,20,28,36,20,28,36])})\n",
    "df_types[\"MAE\"] = \"\"\n",
    "df_types[\"IC MAE\"] = \"\"\n",
    "df_types[\"MSE\"] = \"\"\n",
    "df_types[\"IC MSE\"] = \"\"\n",
    "df_types[\"RMSE\"] = \"\"\n",
    "df_types[\"IC RMSE\"] = \"\"\n",
    "df_types[\"R2\"] = \"\"\n",
    "df_types[\"IC R2\"] = \"\"\n",
    "df_types.set_index(['N. de capas ocultas','Neuronas por capa'], inplace=False)\n",
    "#df_types.sort_index(inplace=True)\n",
    "\n",
    "epochs = 1\n",
    "index = 0\n",
    "maxLayers = 3\n",
    "neurons = [20,28,36]\n",
    "for i in range(maxLayers):\n",
    "    layers = i+1\n",
    "    for j in range(np.size(neurons)):\n",
    "        mae, std_mae, mse, std_mse, rmse, std_rmse, r2, std_r2 = ANN(layers, neurons[j], epochs)\n",
    "        df_types[\"MAE\"][index] = round(mae, 3)\n",
    "        df_types[\"IC MAE\"][index] = round(std_mae, 3)\n",
    "        df_types[\"MSE\"][index] = round(mse, 3)\n",
    "        df_types[\"IC MSE\"][index] = round(std_mse, 3)\n",
    "        df_types[\"RMSE\"][index] = round(rmse, 3)\n",
    "        df_types[\"IC RMSE\"][index] = round(std_rmse, 3)\n",
    "        df_types[\"R2\"][index] = round(r2, 3)\n",
    "        df_types[\"IC R2\"][index] = round(std_r2, 3)\n",
    "        index += 1\n",
    "\n",
    "qgrid_widget = qgrid.show_grid(df_types, show_toolbar=False)\n",
    "qgrid_widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 1500\n",
    "maxLayers = 3\n",
    "neurons = [10,20,32]\n",
    "for i in range(maxLayers):\n",
    "    layers = i+1\n",
    "    for j in range(np.size(neurons)):\n",
    "        n = neurons[j]\n",
    "        mae, std_mae, mse, std_mse, rmse, std_rmse, r2, std_r2 = ANN(layers, n, epochs)\n",
    "        print('layers: ' + str(layers) + ', neurons: ' + str(n))\n",
    "        print('MAE: ' + str(round(mae,3)) + ' +- ' + str(round(std_mae,3)))\n",
    "        print('MSE: ' + str(round(mse,3)) + ' +- ' + str(round(std_mse,3)))\n",
    "        print('RMSE: ' + str(round(rmse,3)) + ' +- ' + str(round(std_rmse,3)))\n",
    "        print('R2: ' + str(round(r2,3)) + ' +- ' + str(round(std_r2,3)))\n",
    "        print('\\n')\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "def RF(trees, features):\n",
    "    iterations = 10\n",
    "    random.seed(19680801)\n",
    "    errorMAE = np.zeros(iterations)\n",
    "    errorR2 = np.zeros(iterations)\n",
    "\n",
    "    gss = GroupShuffleSplit(n_splits=iterations, train_size=.7)\n",
    "    j=0\n",
    "    for train_idx, test_idx in gss.split(X, Y, G):\n",
    "        Xtrain = X[train_idx,:]\n",
    "        Ytrain = Y[train_idx]\n",
    "        Xtest = X[test_idx,:]\n",
    "        Ytest = Y[test_idx]\n",
    "\n",
    "        #Normalizamos los datos\n",
    "        media = np.mean(Xtrain)\n",
    "        desvia = np.std(Xtrain)\n",
    "        Xtrain = sc.stats.stats.zscore(Xtrain)\n",
    "        Xtest = (Xtest - np.matlib.repmat(media, Xtest.shape[0], 1))/np.matlib.repmat(desvia, Xtest.shape[0], 1)\n",
    "\n",
    "        #Creación del modelo y entrenamiento\n",
    "        model = RandomForestRegressor(n_estimators=trees, max_features=features).fit(Xtrain, Ytrain)\n",
    "        \n",
    "        #Validación\n",
    "        Yest = model.predict(Xtest)\n",
    "        \n",
    "        #Evaluación de las predicciones\n",
    "        errorMAE[j] = MAE(Yest,Ytest)\n",
    "        errorR2[j] = R2(Yest,Ytest)\n",
    "        j += 1\n",
    "    \n",
    "    return(np.mean(errorMAE), np.std(errorMAE), np.mean(errorR2), np.std(errorR2))\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF(25, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resultados RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import qgrid\n",
    "randn = np.random.randn\n",
    "df_types = pd.DataFrame({\n",
    "    'Numero de arboles' : pd.Series([5,5,5,10,10,10,20,20,20,50,50,50]), \n",
    "    'Variables analizadas por nodo' : pd.Series([5,10,15,5,10,15,5,10,15,5,10,15])})\n",
    "df_types[\"MAE\"] = \"\"\n",
    "df_types[\"IC MAE\"] = \"\"\n",
    "df_types[\"R2\"] = \"\"\n",
    "df_types[\"IC R2\"] = \"\"\n",
    "df_types.set_index(['Numero de arboles','Variables analizadas por nodo'], inplace=False)\n",
    "#df_types.sort_index(inplace=True)\n",
    "\n",
    "index = 0\n",
    "trees = np.array([5,10,20,50])\n",
    "maxFeatures = np.array([5,10,15])\n",
    "for i in range(np.size(trees)):\n",
    "    est = trees[i]\n",
    "    for j in range(np.size(maxFeatures)):\n",
    "        mae, std_mae, r2, std_r2 = RF(est, maxFeatures[j])\n",
    "        df_types[\"MAE\"][index] = round(mae, 3)\n",
    "        df_types[\"IC MAE\"][index] = round(std_mae, 3)\n",
    "        df_types[\"R2\"][index] = round(r2, 3)\n",
    "        df_types[\"IC R2\"][index] = round(std_r2, 3)\n",
    "        index += 1\n",
    "\n",
    "qgrid_widget = qgrid.show_grid(df_types, show_toolbar=False)\n",
    "qgrid_widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trees = [5,10,20,50,100]\n",
    "maxFeatures = [5,10,15]\n",
    "for i in range(np.size(trees)):\n",
    "    est = trees[i]\n",
    "    for j in range(np.size(maxFeatures)):\n",
    "        features = maxFeatures[j]\n",
    "        mae, std_mae, r2, std_r2 = RF(est, maxFeatures[j])\n",
    "        print('trees: ' + str(est) + ', features: ' + str(features))\n",
    "        print('MAE: ' + str(round(mae,3)) + ' +- ' + str(round(std_mae,3)))\n",
    "        print('R2: ' + str(round(r2,3)) + ' +- ' + str(round(std_r2,3)))\n",
    "        print('\\n')\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
